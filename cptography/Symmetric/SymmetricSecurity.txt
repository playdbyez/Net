##### [] Security Metrics [] #####

Since Information Theory is fundamental to computer science, it is essential to distinguish between
information-theoretic security and computational security

A cryptographic system is deemed computationally secure if the best known algorithm for breaking it requires
more than an unfeasable ammount of operations (2¹²⁸), although it can still be broken if there is a better unknown algorithm.
These systems also require being provably secure.

A cryptographic system is deemed unconditionally secure if it cannot be broken even with infinite computing power.

>> Not Computationally Secure
  Shift cipher
  Substitution cipher
  Vigenere cipher
  Enigma machine

>> Not Unconditionally secure
  DES
  AES
  RSA
  ElGamal encryption

 ########################### :: Probability :: #########################################
We can compute the conditional of a likely character being represented by said cipher, given that we know that the order in which the secrete keys vary based on a pre-discovered distribution probability of each key.
Thus, previous knowledge of the encryption function and the probability distribution of each key within the set of keys and of each character within the message are required in order to piece some information about the message once the cipher is public.
 
FORMULA
 
PROABILITY
p(P = m) = 0
**probability of (P)laintext being equal to the target (m)essage equals zero
 
JOINT PROBABILITY DISTRIBUTION
X and Y are random varibles
for i and n >= 1
for j and n >= 1
rᵢⱼ = p (X = x[i] and Y = y[j])
 
 
 
#####################################################################################################

::: Previously known associated probabilities :::

[Key Probability]
Key space is K = {k1, k2, k3} with probability of being used per message character occurring at rate :
p(K = k1) = 0.25 = 1/4 of the time
p(K = k2) = 0.5  = 1/2 of the time
p(K = k3) = 0.25 = 1/4 of the time



[Plain Probability]
Message space is P = {a,b,c,d} with probability of being used as the message character occurring at rate :
p(P = a) = 0.25 = 1/4  of the time
p(P = b) = 0.3  = 3/10 of the time
p(P = c) = 0.15 = 3/20 of the time
p(P = d) = 0.3  = 3/10 of the time
 
Cipher text is  C = {1,2,3,4} with the encryption function of combinations occurring at rate :
      a    b    c    d
k1    3    4    2    1
k2    3    1    4    2
k3    4    3    1    2
 


[Cipher Probability]
The above gives us the means to calculate the probability distribution per cipher character via the formula bellow:
p(C=c) = Σ(k:c∈C(k)) p(K =k) x p(P = dₖ(c)) 
 
Hence
p(C = 1) = p(k1) x p(d) + p(k2) x p(b) + p(k3) x p(c) = 0.2625
p(C = 2) = p(k1) x p(c) + p(k2) x p(d) + p(k3) x p(d) = 0.2625
p(C = 3) = p(k1) x p(a) + p(k2) x p(a) + p(k3) x p(b) = 0.2625
p(C = 4) = p(k1) x p(b) + p(k2) x p(c) + p(k3) x p(a) = 0.2125


###################################################################################################################################
 
[Fortification Method]
From a defense point of view that knows the encryption table, 
given said input m, what is the probability of a specific c being the output cipher?
FORMULA
p(C=c | P=m) =  Σ(k:m=dₖ(c)) p(K =k)
 
RESULTS
p(C=1 | P=a ) = 0
p(C=1 | P=b ) = p(k1) = 0.5
p(C=1 | P=c ) = p(k3) = 0.25
p(C=1 | P=d ) = p(k1) = 0.25
 
p(C=2 | P=a ) = 0
p(C=2 | P=b ) = 0
p(C=2 | P=c ) = p(k1) = 0.25
p(C=2 | P=d ) = 0.75
 
p(C=3 | P=a ) = p(k1) + p (k2) = 0.75
p(C=3 | P=b ) = p(k3) = 0.25
p(C=3 | P=c ) = 0
p(C=3 | P=d ) = 0
 
p(C=4 | P=a ) = p(k3) = 0.25
p(C=4 | P=b ) = p(k1) = 0.25
p(C=4 | P=c ) = p(k2) = 0.25
p(C=4 | P=d ) = 0
 
 
 
[Estimation Method]
From an attacking point of view that knows the encryption table, 
given that c is the cipher character then what could m probably be?
FORMULA
p(P=m | C=c) = p(P=m) x p(C=c| P=m) / p(C=c)
 
RESULTS
p(P=a | C=1) = 0
p(P=a | C=2) = 0
p(P=a | C=3) = 0.714
p(P=a | C=4) = 0.294
 
p(P=b | C=1) = 0.143
p(P=b | C=2) = 0
p(P=b | C=3) = 0.286
p(P=b | C=4) = 0.352
 
p(P=c | C=1) = 0.571
p(P=c | C=2) = 0.143
p(P=c | C=3) = 0
p(P=c | C=4) = 0.352
 
p(P=d | C=1) = 0.286
p(P=d | C=2) = 0.857
p(P=d | C=3) = 0
p(P=d | C=4) = 0




################################### :: Entropy :: ############################################ [ A Mathematical Theory of Communication ~ 1948]

Information = Uncertainty

Entropy measures the ammount of uncertainty in a random variable.
Also known as Shannon entropy, which quantifies the expected value of a message's information.
Thus H(X) will calculate the ammount of information a variable X can reveal based on the certainty of its behaviour
against a condition with finite outcome of length n.

[] H(X) >= 0 always (entropy's lower bound)
[] H(X) only equals 0 if a pᵢ = 0 and a different pᵢ = 1
[] if pᵢ = 1/n for all ᵢ then H(X) = log2(n)

FORMULA

H(X) = - ᵢ₌₁Σⁿ pᵢ x log2(pᵢ)
where pᵢ = (X = xᵢ)
while removing the minus = ᵢ₌₁Σⁿ p(X = xᵢ) x log2(1/p(X = xᵢ)) 



[ CASE 1 ]
If you know my answer every time then it contains no information and certainly its entropy H(X) = 0
p1 = 1
p2 = 0
H(X) = (-1 x log2(1) ) (-0 x log2(0) ) = 0



[ CASE 2 ]
If you dont know my answer and I have equal probability of choosing between two options
then my answer contains one bit of information and its entropy H(X) = 1
p1 = 1/2
p2 = p1
H(X) = - (log2(1/2) / 2 ) - (log2(1/2) / 2) = 1 

[ CASE 3 ]
If the number of choices is 26 and my answers are unknown with equal probability of choice per option 
and said option can also be repeated,then the entropy per choice is H(X) = log2(n)
pᵢ = 1/n for all ᵢ
H(X) = log2(26) = 4.70


[] Joint entropy



[] Key Equivocation
Aims at determining if a system leaks information about the key based on how much information about said key is revealed after a single ciphertext is observed.
Information is measured as bits derived from the probability distribution of ciphertext p(C = c), key distribution p(K = k) and plaintext distribution p(P = m).






############################# [] Perfect Secrecy [] ######################################
A system in which the public cipher gives no information about the message.
Knowing the cipher equivalent reveals no information.

if the probability that one character from the encrypted message is equal to M when we know the cipher is equal to C,
is the same as the probability that the character is M withouth knowing that the cipher is C.
The cipher has perfect secrecy.

FORMULA
p( C = c | P = m ) = p (C = c)
// the probability of c being a certain cipher and the probability of a message character being a certain letter
// is equal to the probability that the cipher is a certain cipher



>## Shannon's Theorem ##<
Defines a perfectly secure system if
  - The key is unique per message
  - The ammount of keys is equal to the length of the message
  - every key is used with equal probability 1 /#K

Examples of perfect secrecy within symmetric schemes can be found on
  - Modified Shift Cipher
  - One-Time Pad Cipher



#K = set of key characters      (k)
#P = set of message characters  (m)
#C = set of cipher characters   (c)

Since each key is used with equal probability, we must define the probability of each cipher p(C = c).

p( C = c ) = Σₖ p(K = k) x p(P = dₖ(c))
           = 1 / #K Σₖ  p(P = dₖ(c))

Since each message character uses an unique key

Σₖ p(P = dₖ(c)) = Σₚ p (P = m) = 1

hence  p(C = c) = 1/#K

Since c = eₖ(m) then  p (C = C | P = m) = p(K = k) = 1/#K

Through Bayes' Theorem 
p(P = m | C = c) = p(P = m) x p (C = c | P = m) / p(C = c)
                 = (p(P = m) x 1/#K) / (1/#K)
                 = p(P = m)


The main issue with a scheme with perfect secrecy as defined by Claude Shannon relates to key distribution issues,
given that each key must be generated per message.

###### One-time Pad Sytems ####
5-UCO



